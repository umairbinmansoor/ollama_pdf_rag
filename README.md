# Chat with PDF locally with Ollama demo ðŸš€

This is a demo (accompanying the YouTube tutorial below) Jupyter Notebook showcasing a simple local RAG (Retrieval Augmented Generation) pipeline for chatting with PDFs.

<a href="https://youtu.be/ztBJqzBU5kc">
  <img src="https://img.youtube.com/vi/ztBJqzBU5kc/hqdefault.jpg" alt="Watch the video" width="100%">
</a>

If you have any questions or suggestions, please feel free to create an issue in this repository or comment on the YouTube video; I will do my best to respond.

Thank you for watching, and I hope you found this resource useful! ðŸ˜Š

## Running the Streamlit application

1. **Clone repo**: Run this in your terminal 

      ```bash
      git clone https://github.com/tonykipkemboi/ollama_pdf_rag.git
      ```

2. **Install Dependencies**: Execute to install dependencies
  
      ```bash
      pip install -r requirements.txt
      ```

3. **Launch the App**: Run to start the Streamlit interface on `localhost`

      ```bash
      streamlit run streamlit_app.py
      ``` 
